{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节的网络需要较长的训练时间\n",
    "# 可以在Kaggle访问：\n",
    "# https://www.kaggle.com/boyuai/boyu-d2l-image-classification-cifar-10\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/cifar10'\n",
    "                                            , transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [d[0].data.cpu().numpy() for d in trainset]\n",
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像增强\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #先四周填充0，再把图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4731, 0.4822, 0.4465), (0.2212, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4731, 0.4822, 0.4465), (0.2212, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/kesci/input/CIFAR102891/cifar-10/train'\n",
    "test_dir = '/home/kesci/input/CIFAR102891/cifar-10/test'\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=test_dir, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'forg', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):   # 我们定义网络时一般是继承的torch.nn.Module创建新的子类\n",
    "\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        #torch.nn.Sequential是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False), \n",
    "            # 添加第一个卷积层,调用了nn里面的Conv2d（）\n",
    "            nn.BatchNorm2d(outchannel), # 进行数据的归一化处理\n",
    "            nn.ReLU(inplace=True), # 修正线性单元，是一种人工神经网络中常用的激活函数\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential() \n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "        #  便于之后的联合,要判断Y = self.left(X)的形状是否与X相同\n",
    "\n",
    "    def forward(self, x): # 将两个模块的特征进行结合，并使用ReLU激活函数得到最终的特征。\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential( # 用3个3x3的卷积核代替7x7的卷积核，减少模型参数\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        ) \n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #第一个ResidualBlock的步幅由make_layer的函数参数stride指定\n",
    "        # ，后续的num_blocks-1个ResidualBlock步幅是1\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 超参数设置\n",
    "EPOCH = 20   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "LR = 0.1        #学习率\n",
    "\n",
    "# 模型定义-ResNet\n",
    "net = ResNet18().to(device)\n",
    "\n",
    "# 定义损失函数和优化方式\n",
    "criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) \n",
    "#优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n",
    "\n",
    "# 训练\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start Training, Resnet-18!\")\n",
    "    num_iters = 0\n",
    "    for epoch in range(pre_epoch, EPOCH):\n",
    "        print('\\nEpoch: %d' % (epoch + 1))\n",
    "        net.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0): \n",
    "            #用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，\n",
    "            #下标起始位置为0，返回 enumerate(枚举) 对象。\n",
    "            \n",
    "            num_iters += 1\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1) #选出每一列中最大的值作为预测结果\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # 每20个batch打印一次loss和准确率\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "                        % (epoch + 1, num_iters, sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "    print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
