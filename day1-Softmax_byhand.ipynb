{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:17:26.107302Z",
     "start_time": "2020-02-12T14:17:26.100952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n",
      "0.4.2\n"
     ]
    }
   ],
   "source": [
    "# import needed package\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:50.809014Z",
     "start_time": "2020-02-12T14:09:50.779631Z"
    }
   },
   "outputs": [],
   "source": [
    "#准备数据集\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='/mnt1/from_old_machine_P40_M1/zzzzzth/DL/data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='/mnt1/from_old_machine_P40_M1/zzzzzth/DL/data/', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:51.853448Z",
     "start_time": "2020-02-12T14:09:51.850426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# show result \n",
    "print(type(mnist_train))\n",
    "print(len(mnist_train), len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:52.633756Z",
     "start_time": "2020-02-12T14:09:52.629483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "# 可以通过下标来访问任意一个样本\n",
    "feature, label = mnist_train[0]\n",
    "print(feature.shape, label)  # Channel x Height x Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:53.854450Z",
     "start_time": "2020-02-12T14:09:53.822795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB90lEQVR4nF2QvWvTURSGn3PuTUwaSVMtlLZDBT+g0CragnQQwcnFQRAcdHNy0KngXyAIDg5O4qKuDrrp4ChFOthBsNrSxZZ0MMXYD5tffvfe45CkX2d9eF7e9wgAYsD487cL7Xzi5srTJvsnwMUnyz/WGmZmPxfT+qvJPQDVN+d1ezdPvn8nGZTKxc939+CnsY3kg6C5ooDY8PVF8ABTYw3vyiN9mvsohbC1Foj3Zrvm7MNGcvFFfW1kXfPi8UsPGr7qT4EC3ArOSuFlPvXhcnlocPNZ9KV/I+e6sRdW3TGqfNwZn313w3+dCpWYfs0s4YHJ30FdeYOJbPix5DJDfTSl1pXXeOBReTuWW2H65InCUN4q1m4P7PZLcboTOzd0plpZjl9Sis5L1K2litP6+97OgbP3r672NwsOEG31f7sDdAvxZz67ZsWKS4ikUrs01/mrAkgR23LJujmOJk560HJW/voMExCyApuo9SDKbtuCExNRbXuJB2IxUjRTMRVRS5qwfQiMijMRAM3FHTaJFBERJBWCFY6YLRc0mUvmfaR20AQSCKhgYqHcMX0PKlgHqoU+DnzIAAcmOEw0Hiok0BYhSVQwie5IIdRQFaTjH55SJ2RZ3s6ydo65I4VqFT+oWoTgVvtOo2kPirHwvVlAt01CymvzJID/CjnVF438ZwEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7EFCB8A7C588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显示\n",
    "mnist_PIL = torchvision.datasets.FashionMNIST(root='/mnt1/from_old_machine_P40_M1/zzzzzth/DL/data', train=True, download=True)\n",
    "PIL_feature, label = mnist_PIL[1]\n",
    "print(label)\n",
    "PIL_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:56.039325Z",
     "start_time": "2020-02-12T14:09:56.036072Z"
    }
   },
   "outputs": [],
   "source": [
    "# 该函数已保存在d2lzh包中\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:09:57.766415Z",
     "start_time": "2020-02-12T14:09:57.761874Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    d2l.use_svg_display()\n",
    "    # _ 表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(14, 14))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:10:18.091866Z",
     "start_time": "2020-02-12T14:10:18.089764Z"
    }
   },
   "outputs": [],
   "source": [
    "#有显示bug\n",
    "# X, y = [], []\n",
    "# for i in range(10):\n",
    "#     X.append(mnist_train[i][0]) # 将第i个feature加到X中\n",
    "#     y.append(mnist_train[i][1]) # 将第i个label加到y中\n",
    "# show_fashion_mnist(X, get_fashion_mnist_labels(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:10:35.909335Z",
     "start_time": "2020-02-12T14:10:35.905863Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:11:03.125725Z",
     "start_time": "2020-02-12T14:11:01.365344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76 sec\n"
     ]
    }
   ],
   "source": [
    "#计时\n",
    "start = time.time()\n",
    "for X, y in train_iter:\n",
    "    continue\n",
    "print('%.2f sec' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于softmax训练分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:18:21.852729Z",
     "start_time": "2020-02-12T14:18:21.849062Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float, requires_grad= True)\n",
    "b = torch.zeros(num_outputs, dtype=torch.float, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:28:40.713559Z",
     "start_time": "2020-02-12T14:28:40.708066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9]])\n",
      "tensor([[ 6],\n",
      "        [15]])\n",
      "tensor([5, 7, 9])\n",
      "tensor([ 6, 15])\n"
     ]
    }
   ],
   "source": [
    "#tensor求和机制\n",
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(X.sum(dim=0, keepdim=True))  # dim为0，按照相同的列求和，并在结果中保留列特征\n",
    "print(X.sum(dim=1, keepdim=True))  # dim为1，按照相同的行求和，并在结果中保留行特征\n",
    "print(X.sum(dim=0, keepdim=False)) # dim为0，按照相同的列求和，不在结果中保留列特征\n",
    "print(X.sum(dim=1, keepdim=False)) # dim为1，按照相同的行求和，不在结果中保留行特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:01:50.000366Z",
     "start_time": "2020-02-12T17:01:49.997332Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x_exp = x.exp()\n",
    "    partition = x_exp.sum(dim=1, keepdim=True)\n",
    "#     print(\"x size is \", x_exp.size())\n",
    "#     print(\"partition size is \", partition, partition.size())\n",
    "    return x_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:38.080408Z",
     "start_time": "2020-02-12T17:02:38.075740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1975, 0.1894, 0.2217, 0.2782, 0.1132],\n",
      "        [0.1335, 0.1965, 0.2372, 0.2517, 0.1811]]) \n",
      " tensor([1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 5))\n",
    "x_prob = softmax(x)\n",
    "print(x_prob, '\\n', x_prob.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:45.047521Z",
     "start_time": "2020-02-12T17:02:45.044715Z"
    }
   },
   "outputs": [],
   "source": [
    "def net(x):\n",
    "    return softmax(torch.mm(x.view((-1, num_inputs)), w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:50.903323Z",
     "start_time": "2020-02-12T17:02:50.897790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.5000]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = torch.LongTensor([0, 2])\n",
    "y_hat.gather(1, y.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:51.802085Z",
     "start_time": "2020-02-12T17:02:51.796714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000],\n",
      "        [0.5000]])\n",
      "tensor([[0.1000, 0.2000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y1 = torch.LongTensor([0, 2])\n",
    "print(y_hat.gather(1, y1.view(-1,1))) #按行\n",
    "y2 = torch.LongTensor([0, 1, 1])\n",
    "print(y_hat.gather(0, y2.view(1,-1))) #按列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:54.607509Z",
     "start_time": "2020-02-12T17:02:54.604694Z"
    }
   },
   "outputs": [],
   "source": [
    "#交叉熵损失函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:56.066726Z",
     "start_time": "2020-02-12T17:02:56.064071Z"
    }
   },
   "outputs": [],
   "source": [
    "#准确率\n",
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:02:58.937008Z",
     "start_time": "2020-02-12T17:02:58.933396Z"
    }
   },
   "outputs": [],
   "source": [
    "# 已写在d2lzh_pytorch包中方便以后使用\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        acc_sum += (net(x).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:03:10.133617Z",
     "start_time": "2020-02-12T17:03:05.219564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1115\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_accuracy(test_iter, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:07:15.144204Z",
     "start_time": "2020-02-12T17:04:19.469901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7864, train acc 0.749, test acc 0.792\n",
      "epoch 2, loss 0.5697, train acc 0.814, test acc 0.811\n",
      "epoch 3, loss 0.5260, train acc 0.825, test acc 0.817\n",
      "epoch 4, loss 0.5010, train acc 0.832, test acc 0.823\n",
      "epoch 5, loss 0.4860, train acc 0.836, test acc 0.825\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "# 函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                d2l.sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step() \n",
    "            \n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [w, b], lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.3.1",
   "language": "python",
   "name": "torch-1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
