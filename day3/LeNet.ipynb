{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:38:33.587205Z",
     "start_time": "2020-02-16T08:38:33.583934Z"
    }
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import d2lzh_pytorch as d2l\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:24:10.323636Z",
     "start_time": "2020-02-16T08:24:10.315106Z"
    }
   },
   "outputs": [],
   "source": [
    "#net\n",
    "class Flatten(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Reshape(torch.nn.Module): #将图像大小重定型\n",
    "    def forward(self, x):\n",
    "        return x.view(-1,1,28,28)      #(B x C x H x W)\n",
    "    \n",
    "net = torch.nn.Sequential(     #Lelet                                                  \n",
    "    Reshape(),\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28\n",
    "    nn.Sigmoid(),                                                       \n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5\n",
    "    Flatten(),                                                          #b*16*5*5   => b*400\n",
    "    nn.Linear(in_features=16*5*5, out_features=120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:29:39.374921Z",
     "start_time": "2020-02-16T08:29:39.113604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape output shape: \t torch.Size([1, 1, 28, 28])\n",
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#print\n",
    "X = torch.randn(size=(1,1,28,28), dtype = torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:36:02.324913Z",
     "start_time": "2020-02-16T08:36:02.277840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(\n",
    "    batch_size=batch_size, root='../data/')\n",
    "print(len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:38:53.326256Z",
     "start_time": "2020-02-16T08:38:53.321925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function has been saved in the d2l package for future use\n",
    "#use GPU\n",
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:39:15.882147Z",
     "start_time": "2020-02-16T08:39:15.876893Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算准确率\n",
    "'''\n",
    "(1). net.train()\n",
    "  启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为True\n",
    "(2). net.eval()\n",
    "不启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为False\n",
    "'''\n",
    "\n",
    "def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
    "    for X,y in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:49:11.493009Z",
     "start_time": "2020-02-16T08:49:11.485423Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        n, start = 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device),y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:50:13.774750Z",
     "start_time": "2020-02-16T08:50:13.455094Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "lr, num_epochs = 0.9, 10\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\n",
    "train_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "for testdata,testlabe in test_iter:\n",
    "    testdata,testlabe = testdata.to(device),testlabe.to(device)\n",
    "    break\n",
    "print(testdata.shape,testlabe.shape)\n",
    "net.eval()\n",
    "y_pre = net(testdata)\n",
    "print(torch.argmax(y_pre,dim=1)[:10])\n",
    "print(testlabe[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.3.1",
   "language": "python",
   "name": "torch-1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
